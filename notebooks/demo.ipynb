{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Demonstration Notebook\n",
    "\n",
    "This notebook runs LLM inference to predict HPO terms, compares them to ground truth phenopackets, and produces a summary report."
   ],
   "id": "26962e4431228f20"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Step 0) Imports, Path Discovery, & Sanity Checks\n",
    "\n",
    "Load all dependencies, discover the dataset CSV automatically, and validate critical directories."
   ],
   "id": "ce6e95e32c2fa9b3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Basic Setup\n",
    "import sys, os, glob, json, subprocess, pickle, datetime, hashlib, warnings, random, requests\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from typing import List, Dict, Any\n",
    "from ollama import chat\n",
    "from docling.document_converter import DocumentConverter, ConversionError\n",
    "from pypdfium2._helpers.misc import PdfiumError\n",
    "from google.protobuf.json_format import ParseDict, ParseError\n",
    "from phenopackets import Phenopacket as ProtoPhenopacket\n",
    "from json.decoder import JSONDecodeError\n",
    "\n",
    "# Need this at least once for some reason:\n",
    "# import .autonotebook\n",
    "# from .autonotebook import tqdm as notebook_tqdm\n",
    "\n",
    "# Setup the PYTHONPATH for this project demonstration\n",
    "# Make sure our utils folder is on PYTHONPATH\n",
    "project_root        = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "src_folder          = os.path.join(project_root, \"src\")\n",
    "utils_folder        = os.path.join(project_root, \"notebooks\", \"utils\")\n",
    "\n",
    "for path in (src_folder, utils_folder):\n",
    "    if not os.path.isdir(path):\n",
    "        raise FileNotFoundError(f\"Expected folder on PYTHOPATH : {path}\")\n",
    "    if path not in sys.path:\n",
    "        sys.path.insert(0, path)\n",
    "\n",
    "print(\"PYTHONPATH patched with:\", src_folder, utils_folder)\n",
    "\n",
    "print(\"Project Start:       %s\" % project_root)\n",
    "print(\"Source Folder:       %s\" % src_folder)\n",
    "print(\"Utilities Folder:    %s\" % utils_folder)\n",
    "\n",
    "try:\n",
    "    from phenopacket import Phenopacket, InvalidPhenopacketError\n",
    "    from report import Report\n",
    "    from evaluation import PhenotypeEvaluator\n",
    "except ImportError as e:\n",
    "    raise ImportError(f\"Could not import project utils: {e}\")\n",
    "\n",
    "# define all key paths\n",
    "pdf_input_directory                 = os.path.join(src_folder, \"P5\", \"scripts\", \"data\", \"tmp\", \"phenopacket_store\", \"pmid_pdfs\")            # scripts/data/tmp/phenopacket_store/pmid_pdfs/\n",
    "ground_truth_notebooks_directory    = os.path.join(src_folder, \"P5\", \"scripts\", \"data\",\"tmp\", \"phenopacket_store\",\"notebooks\")              # scripts/data/tmp/phenopacket_store/notebooks/\n",
    "dataset_csv_path                    = os.path.join(src_folder, \"P5\", \"scripts\", \"data\", \"tmp\", \"PMID_PDF_Phenopacket_list_in_phenopacket_store.csv\")\n",
    "\n",
    "# All experimental outputs go under here\n",
    "experimental_data_root              = os.path.join(project_root, \"experimental-data\")\n",
    "llm_output_directory                = os.path.join(experimental_data_root, \"llm_output_dir\")                                                # intermediate .txt + raw JSON from LLM\n",
    "validated_jsons_directory           = os.path.join(experimental_data_root, \"validated_jsons\")                                               # validated_jsons, the final validated LLM phenopackets\n",
    "evaluation_report_output_path       = os.path.join(project_root, \"reports\", \"first_report.json\")                                            # the evaluation metrics report\n",
    "\n",
    "# Create any missing output folders\n",
    "os.makedirs(pdf_input_directory, exist_ok=True)\n",
    "os.makedirs(ground_truth_notebooks_directory, exist_ok=True)\n",
    "os.makedirs(os.path.dirname(dataset_csv_path), exist_ok=True)\n",
    "os.makedirs(llm_output_directory, exist_ok=True)\n",
    "os.makedirs(validated_jsons_directory, exist_ok=True)\n",
    "os.makedirs(os.path.dirname(evaluation_report_output_path), exist_ok=True)\n",
    "\n",
    "# Create the PMIDs pickle file path\n",
    "pmid_pkl_path = os.path.join(src_folder, \"P5\", \"scripts\", \"data\", \"tmp\", \"pmids.pkl\")\n",
    "\n",
    "# TODO: Figure out why deleting the `ground_truth_notebooks_directory` after creating it works. Maybe because git doesn't let me just overwrite a directory with a clone request\n",
    "# Before the git pull operation\n",
    "import shutil\n",
    "\n",
    "# Clean up existing directory if it exists\n",
    "target_dir = os.path.join(src_folder, \"P5\", \"scripts\", \"data\", \"tmp\", \"phenopacket_store\", \"notebooks\")\n",
    "if os.path.exists(target_dir):\n",
    "    shutil.rmtree(target_dir)\n",
    "\n",
    "# 1. Now run the git pull to clone the \"phenopacket-store\" GitHub repo into scripts/data/tmp/phenopacket_store\n",
    "subprocess.run([\n",
    "    sys.executable, \"-m\", \"P5.scripts.pull_git_files\",\n",
    "    os.path.join(src_folder, \"P5\", \"scripts\", \"data\", \"tmp\", \"phenopacket_store\"),\n",
    "    \"https://github.com/monarch-initiative/phenopacket-store.git\",\n",
    "    \"notebooks\"\n",
    "], check=True)\n",
    "\n",
    "print(\"Stage 1 Complete, Produced %s\" % ground_truth_notebooks_directory)\n",
    "\n",
    "# 2. Scan the just-pulled notebooks for PMID_##### files\n",
    "subprocess.run([\n",
    "    sys.executable, \"-m\", \"P5.scripts.create_pmid_pkl\",\n",
    "    os.path.join(src_folder, \"P5\", \"scripts\", \"data\", \"tmp\", \"phenopacket_store\", \"notebooks\"),\n",
    "    os.path.join(src_folder, \"P5\", \"scripts\", \"data\", \"tmp\", \"pmids.pkl\"),\n",
    "    \"--recursive_dir_search\",\n",
    "], check=True)\n",
    "\n",
    "print(\"Stage 2 Complete\")\n",
    "\n",
    "# 3. Download *all* PDFs for those PMIDs (0 = unlimited)\n",
    "subprocess.run([\n",
    "    sys.executable, \"-m\", \"P5.scripts.pmid_downloader\", pmid_pkl_path, pdf_input_directory, \"10\"\n",
    "], check=True)\n",
    "\n",
    "print(\"Stage 3 Complete\")\n",
    "\n",
    "# 4. Finally, build THE CSV mapping PDFs to the ground-truth JSONs\n",
    "if not os.path.isfile(dataset_csv_path):\n",
    "    subprocess.run([\n",
    "        sys.executable, \"-m\", \"P5.scripts.create_phenopacket_dataset\",\n",
    "        pdf_input_directory,\n",
    "        ground_truth_notebooks_directory,\n",
    "        dataset_csv_path,\n",
    "        \"--recursive_ground_truth_dir\", \"True\"\n",
    "    ], check=True)\n",
    "    print(f\"Created dataset CSV at {dataset_csv_path}\")\n",
    "\n",
    "    print(\"Stage 4 Complete\")\n",
    "\n",
    "    if not os.path.isdir(pdf_input_directory):\n",
    "        raise FileNotFoundError(\"PDF input directory not found: %s\" % pdf_input_directory)\n",
    "    if not os.path.isdir(ground_truth_notebooks_directory):\n",
    "        raise FileNotFoundError(\"Ground truth notebooks directory not found: %s\" % ground_truth_notebooks_directory)\n",
    "\n",
    "print(\"Created the PDF inputs folder:                               %s\" % pdf_input_directory)\n",
    "print(\"Created the ground truth folder:                             %s\" % ground_truth_notebooks_directory)\n",
    "print(\"Created the PATH for the CSV of `phenopacket-store`:         %s\" % dataset_csv_path)\n",
    "print(\"Created the PATH for the experimentally generated files:     %s\" % experimental_data_root)\n",
    "print(\"Created the LLM outputs folder:                              %s\" % llm_output_directory)\n",
    "print(\"Created the validated JSONs folder:                          %s\" % validated_jsons_directory)\n",
    "print(\"Created the evaluation report path:                          %s\" % evaluation_report_output_path)\n",
    "\n",
    "print(\"hello0\")  # print hello 0 as a sanity check"
   ],
   "id": "8428cc720c51ed30"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
