{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Model Output Evaluation Notebook\n",
    "\n",
    "This notebook runs LLM inference to predict HPO terms, compares them to ground truth phenopackets, and produces a summary report.\n"
   ],
   "id": "187dea139446c775"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Step 0) Imports, Path Discovery & Sanity Checks\n",
    "\n",
    "Load all dependencies, discover the dataset CSV automatically, and validate critical directories.\n"
   ],
   "id": "298b82d55c7dad0e"
  },
  {
   "cell_type": "code",
   "id": "98ccd760-19a5-48d0-b2c4-64063ecf29e2",
   "metadata": {},
   "source": [
    "# Basic Setup\n",
    "import sys, os, glob, json, subprocess, pickle, datetime, hashlib, warnings, random, requests\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from typing import List, Dict, Any\n",
    "from ollama import chat\n",
    "from docling.document_converter import DocumentConverter, ConversionError\n",
    "from pypdfium2._helpers.misc import PdfiumError\n",
    "from google.protobuf.json_format import ParseDict, ParseError\n",
    "from phenopackets import Phenopacket as ProtoPhenopacket\n",
    "from json.decoder import JSONDecodeError\n",
    "\n",
    "# Need this at least once for some reason:\n",
    "# import .autonotebook\n",
    "# from .autonotebook import tqdm as notebook_tqdm\n",
    "\n",
    "try:\n",
    "    from phenopacket import Phenopacket, InvalidPhenopacketError\n",
    "    from report import Report\n",
    "    from evaluation import PhenotypeEvaluator\n",
    "except ImportError as e:\n",
    "    raise ImportError(f\"Could not import project utils: {e}\")\n",
    "\n",
    "# Make sure our utils folder is on PYTHONPATH\n",
    "project_root        = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "src_folder          = os.path.join(project_root, \"src\")\n",
    "utils_folder        = os.path.join(project_root, \"notebooks\", \"utils\")\n",
    "\n",
    "print(\"Project Start:       %s\" % project_root)\n",
    "print(\"Source Folder:       %s\" % src_folder)\n",
    "print(\"Utilities Folder:    %s\" % utils_folder)\n",
    "\n",
    "for path in (src_folder, utils_folder):\n",
    "    if not os.path.isdir(path):\n",
    "        raise FileNotFoundError(f\"Expected folder on PYTHOPATH : {path}\")\n",
    "    if path not in sys.path:\n",
    "        sys.path.insert(0, path)\n",
    "\n",
    "print(\"PYTHONPATH patched with:\", src_folder, utils_folder)\n",
    "\n",
    "# define all key paths\n",
    "pdf_input_directory                 = os.path.join(src_folder, \"P5\", \"scripts\", \"data\", \"tmp\", \"phenopacket_store\", \"pmid_pdfs\")            # scripts/data/tmp/phenopacket_store/pmid_pdfs/\n",
    "ground_truth_notebooks_directory    = os.path.join(src_folder, \"P5\", \"scripts\", \"data\",\"tmp\", \"phenopacket_store\",\"notebooks\")              # scripts/data/tmp/phenopacket_store/notebooks/\n",
    "dataset_csv_path                    = os.path.join(src_folder, \"P5\", \"scripts\", \"data\", \"tmp\", \"PMID_PDF_Phenopacket_list_in_phenopacket_store.csv\")\n",
    "\n",
    "# All experimental outputs go under here\n",
    "experimental_data_root              = os.path.join(project_root, \"experimental-data\")\n",
    "llm_output_directory                = os.path.join(experimental_data_root, \"llm_output_dir\")                                                # intermediate .txt + raw JSON from LLM\n",
    "validated_jsons_directory           = os.path.join(experimental_data_root, \"validated_jsons\")                                               # validated_jsons, the final validated LLM phenopackets\n",
    "evaluation_report_output_path       = os.path.join(project_root, \"reports\", \"first_report.json\")                                            # the evaluation metrics report\n",
    "\n",
    "# Create any missing output folders\n",
    "os.makedirs(pdf_input_directory, exist_ok=True)\n",
    "os.makedirs(ground_truth_notebooks_directory, exist_ok=True)\n",
    "os.makedirs(os.path.dirname(dataset_csv_path), exist_ok=True)\n",
    "os.makedirs(llm_output_directory, exist_ok=True)\n",
    "os.makedirs(validated_jsons_directory, exist_ok=True)\n",
    "os.makedirs(os.path.dirname(evaluation_report_output_path), exist_ok=True)\n",
    "\n",
    "# Create the PMIDs pickle file path\n",
    "pmid_pkl_path = os.path.join(src_folder, \"P5\", \"scripts\", \"data\", \"tmp\", \"pmids.pkl\")\n",
    "\n",
    "# TODO: Figure out why deleting the `ground_truth_notebooks_directory` after creating it works. Maybe because git doesn't let me just overwrite a directory with a clone request\n",
    "# Before the git pull operation\n",
    "import shutil\n",
    "\n",
    "# Clean up existing directory if it exists\n",
    "target_dir = os.path.join(src_folder, \"P5\", \"scripts\", \"data\", \"tmp\", \"phenopacket_store\", \"notebooks\")\n",
    "if os.path.exists(target_dir):\n",
    "    shutil.rmtree(target_dir)\n",
    "\n",
    "# 1. Now run the git pull to clone the \"phenopacket-store\" GitHub repo into scripts/data/tmp/phenopacket_store\n",
    "subprocess.run([\n",
    "    sys.executable, \"-m\", \"P5.scripts.pull_git_files\",\n",
    "    os.path.join(src_folder, \"P5\", \"scripts\", \"data\", \"tmp\", \"phenopacket_store\"),\n",
    "    \"https://github.com/monarch-initiative/phenopacket-store.git\",\n",
    "    \"notebooks\"\n",
    "], check=True)\n",
    "\n",
    "print(\"Stage 1 Complete, Produced %s\" % ground_truth_notebooks_directory)\n",
    "\n",
    "# 2. Scan the just-pulled notebooks for PMID_##### files\n",
    "subprocess.run([\n",
    "    sys.executable, \"-m\", \"P5.scripts.create_pmid_pkl\",\n",
    "    os.path.join(src_folder, \"P5\", \"scripts\", \"data\", \"tmp\", \"phenopacket_store\", \"notebooks\"),\n",
    "    os.path.join(src_folder, \"P5\", \"scripts\", \"data\", \"tmp\", \"pmids.pkl\"),\n",
    "    \"--recursive_dir_search\",\n",
    "], check=True)\n",
    "\n",
    "print(\"Stage 2 Complete\")\n",
    "\n",
    "# 3. Download *all* PDFs for those PMIDs (0 = unlimited)\n",
    "subprocess.run([\n",
    "    sys.executable, \"-m\", \"P5.scripts.pmid_downloader\", pmid_pkl_path, pdf_input_directory, \"10\"\n",
    "], check=True)\n",
    "\n",
    "print(\"Stage 3 Complete\")\n",
    "\n",
    "# 4. Finally, build THE CSV mapping PDFs to the ground-truth JSONs\n",
    "if not os.path.isfile(dataset_csv_path):\n",
    "    subprocess.run([\n",
    "        sys.executable, \"-m\", \"P5.scripts.create_phenopacket_dataset\",\n",
    "        pdf_input_directory,\n",
    "        ground_truth_notebooks_directory,\n",
    "        dataset_csv_path,\n",
    "        \"--recursive_ground_truth_dir\", \"True\"\n",
    "    ], check=True)\n",
    "    print(f\"Created dataset CSV at {dataset_csv_path}\")\n",
    "\n",
    "    print(\"Stage 4 Complete\")\n",
    "\n",
    "    if not os.path.isdir(pdf_input_directory):\n",
    "        raise FileNotFoundError(\"PDF input directory not found: %s\" % pdf_input_directory)\n",
    "    if not os.path.isdir(ground_truth_notebooks_directory):\n",
    "        raise FileNotFoundError(\"Ground truth notebooks directory not found: %s\" % ground_truth_notebooks_directory)\n",
    "\n",
    "print(\"PDF inputs folder:               %s\" % pdf_input_directory)\n",
    "print(\"Ground truth folder:             %s\" % ground_truth_notebooks_directory)\n",
    "print(\"Dataset CSV path:                %s\" % dataset_csv_path)\n",
    "print(\"Experimentally generated files:  %s\" % experimental_data_root)\n",
    "print(\"LLM outputs folder:              %s\" % llm_output_directory)\n",
    "print(\"Validated JSONs folder:          %s\" % validated_jsons_directory)\n",
    "print(\"Evaluation report path:          %s\" % evaluation_report_output_path)\n",
    "\n",
    "print(\"hello0\")  # print hello 0 as a sanity check"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Step 1) Load Dataset\n",
    "\n",
    "Read the CSV of PMIDs, input paths, and truth paths\n"
   ],
   "id": "dabf5f01d8e6a670"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load datasets\n",
    "dataframe_cases = pd.read_csv(dataset_csv_path)\n",
    "print(f\"Loaded {len(dataframe_cases)} rows from dataset CSV\")\n",
    "# Load cases & deduplicate PMIDs, with start/end counts\n",
    "orig_count = len(dataframe_cases)\n",
    "print(f\"Before deduplication: {orig_count} total cases\")\n",
    "\n",
    "# Debug: verify that every `input` path actually exists\n",
    "print(\"Checking existence of input PDFs:\")\n",
    "for pdf_path in dataframe_cases[\"input\"]:\n",
    "    status = \"FOUND\" if os.path.isfile(pdf_path) else \"MISSING\"\n",
    "    print(f\"  o {pdf_path}: {status}\")\n",
    "\n",
    "# Drop duplicate PMIDs\n",
    "dataframe_cases = dataframe_cases.drop_duplicates(subset=\"pmid\", keep=\"first\").reset_index(drop=True) # This may be too aggressive and I need to check if this is a good approach\n",
    "removed = orig_count - len(dataframe_cases)\n",
    "print(f\"{removed} duplicates removed (now {len(dataframe_cases)} unique PMIDs)\")\n",
    "\n",
    "# Verify required columns\n",
    "required_columns = {\"pmid\", \"input\", \"truth\"}\n",
    "missing_columns = required_columns - set(dataframe_cases.columns)\n",
    "if missing_columns:\n",
    "    raise KeyError(\"Missing required columns: %s\" % missing_columns)\n",
    "\n",
    "# Preview first few rows\n",
    "dataframe_cases.head()\n",
    "\n",
    "\n",
    "print(\"PDF inputs folder:               %s\" % pdf_input_directory)\n",
    "print(\"Ground truth folder:             %s\" % ground_truth_notebooks_directory)\n",
    "print(\"Dataset CSV path:                %s\" % dataset_csv_path)\n",
    "print(\"Experimentally generated files:  %s\" % experimental_data_root)\n",
    "print(\"LLM outputs folder:              %s\" % llm_output_directory)\n",
    "print(\"Validated JSONs folder:          %s\" % validated_jsons_directory)\n",
    "print(\"Evaluation report path:          %s\" % evaluation_report_output_path)\n",
    "print(\"hello1\")  # print hello 1 as a sanity check"
   ],
   "id": "598b33092ab85352",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Step 2) Discover Phenopacket-Store Files\n",
    "\n",
    "Locate all ground-truth Phenopacket JSON files under the `phenopacket_store/notebooks/` directory."
   ],
   "id": "2a1755b2eb294368"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Cache Integrity & Versioning\n",
    "CACHE_DIR = Path(experimental_data_root) / \"text_cache\"\n",
    "INDEX_FILE = CACHE_DIR / \"cache_index.json\"\n",
    "CACHE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def _hash_pdf(pdf_path: Path) -> str:\n",
    "    h = hashlib.sha256()\n",
    "    h.update(pdf_path.read_bytes())\n",
    "    return h.hexdigest()\n",
    "\n",
    "def load_or_update_cache(pmids: list[str], pmid_to_pdf: dict[str, Path]):\n",
    "    if INDEX_FILE.exists():\n",
    "        index = json.loads(INDEX_FILE.read_text())\n",
    "    else:\n",
    "        index = {}\n",
    "    for pmid in pmids:\n",
    "        pdf = pmid_to_pdf[pmid]\n",
    "        digest = _hash_pdf(pdf)\n",
    "        if pmid not in index or index[pmid][\"hash\"] != digest:\n",
    "            text = extract_text_from_pdf(pdf)\n",
    "            with open(CACHE_DIR / f\"{pmid}.pkl\", \"wb\") as fh:\n",
    "                pickle.dump(text, fh)\n",
    "            index[pmid] = {\n",
    "                \"hash\": digest,\n",
    "                \"cached_at\": datetime.datetime.utcnow().isoformat()\n",
    "            }\n",
    "    INDEX_FILE.write_text(json.dumps(index, indent=2))\n",
    "\n",
    "\n",
    "# Finding all ground-truth phenopacket JSON files\n",
    "search_pattern = os.path.join(ground_truth_notebooks_directory, \"*\", \"phenopackets\", \"*.json\")\n",
    "truth_json_filepaths = glob.glob(search_pattern, recursive=True)\n",
    "if not truth_json_filepaths:\n",
    "    raise FileNotFoundError(f\"No ground-truth JSONs found at {search_pattern}\")\n",
    "\n",
    "print(\"Discovered %d ground-truth JSON files\" %len(truth_json_filepaths))\n",
    "\n",
    "\n",
    "print(\"PDF inputs folder:               %s\" % pdf_input_directory)\n",
    "print(\"Ground truth folder:             %s\" % ground_truth_notebooks_directory)\n",
    "print(\"Dataset CSV path:                %s\" % dataset_csv_path)\n",
    "print(\"Experimentally generated files:  %s\" % experimental_data_root)\n",
    "print(\"LLM outputs folder:              %s\" % llm_output_directory)\n",
    "print(\"Validated JSONs folder:          %s\" % validated_jsons_directory)\n",
    "print(\"Evaluation report path:          %s\" % evaluation_report_output_path)\n",
    "print(\"hello2\")  # print hello 2 as a sanity check"
   ],
   "id": "8118b55fc2741c2b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Step 3) Prepare PDF-to-Text Converter\n",
    "\n",
    "- Randomly pick N unique PMIDs from the CSV (from Step 1) to keep runs fast and reproducible.\n",
    "- Instantiate DocumentConverter and define a helper function to load or convert the clinical PDFs for LLM input.\n",
    "- Setup Persistent PDF-to-Text Cache"
   ],
   "id": "9a9faff43b491b26"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Reload the deduplicated CSV from Step 1\n",
    "full_df = pd.read_csv(dataset_csv_path).drop_duplicates(subset=\"pmid\").reset_index(drop=True)\n",
    "\n",
    "# Choose how many cases to sample\n",
    "N = 10\n",
    "# Don’t ask for more than exist\n",
    "N = min(N, len(full_df))\n",
    "subset_df = full_df.sample(n=N, random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(f\"Sampling {N} PMIDs:\", subset_df[\"pmid\"].tolist())\n",
    "\n",
    "\n",
    "# Setup conversion for input material to LLM-compatible txt now\n",
    "\n",
    "# Initialize converter once\n",
    "pdf_to_text_converter = DocumentConverter()\n",
    "\n",
    "# Path to persistent cache of PDF text\n",
    "text_cache_path = os.path.join(experimental_data_root, \"text_cache.pkl\")\n",
    "# Load or initialize cache\n",
    "if os.path.exists(text_cache_path):\n",
    "    with open(text_cache_path, \"rb\") as f:\n",
    "        text_cache = pickle.load(f)\n",
    "    print(f\"Loaded text cache with {len(text_cache)} entries\")\n",
    "else:\n",
    "    text_cache = {}\n",
    "    print(\"Initialized empty text cache\")\n",
    "\n",
    "def load_clinical_pdf(pdf_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Convert .txt or .pdf file at \"pdf_path\" into a plain text string.\n",
    "    Use the in-memory cache first; write new text back to the cache only when the cache is explicitly saved at the end of the pipeline.\n",
    "    Raise FileNotFoundError or ConversionError if the file does not exist.\n",
    "    \"\"\"\n",
    "    # Return cache if it exists in memory\n",
    "    if pdf_path in text_cache:\n",
    "        return text_cache[pdf_path]\n",
    "\n",
    "    # Ensure the files exists before we continue\n",
    "    if not os.path.isfile(pdf_path):\n",
    "        raise FileNotFoundError(\"Input file not found: %s\" % pdf_path)\n",
    "\n",
    "    # If it's already plain text, read and strip any header\n",
    "    if pdf_path.lower().endswith(\".txt\"):\n",
    "        content = open(pdf_path, encoding=\"utf-8\").read()\n",
    "        # Remove any leading markers\n",
    "        return content.split(\"[text]\")[-1]\n",
    "    else:\n",
    "        try:\n",
    "            # Convert PDF to text and handle conversion failures\n",
    "            doc = pdf_to_text_converter.convert(pdf_path)\n",
    "            content = doc.document.export_to_text()\n",
    "        except ConversionError as e:\n",
    "            raise ConversionError(f\"Could not convert {os.path.basename(pdf_path)}: {e}\")\n",
    "\n",
    "\n",
    "    # Save new text in memory and write updated cache to disk later\n",
    "    text_cache[pdf_path] = content\n",
    "    return content\n",
    "\n",
    "# Convert all PDFs in our sampled subset\n",
    "for pdf_path in subset_df[\"input\"]:\n",
    "    pdf_text = load_clinical_pdf(pdf_path)\n",
    "# Persist updated cache to disk\n",
    "with open(text_cache_path, \"wb\") as f:\n",
    "    pickle.dump(text_cache, f)\n",
    "\n",
    "print(f\"Saved text cache now with {len(text_cache)} entries\")\n",
    "\n",
    "\n",
    "print(\"PDF inputs folder:               %s\" % pdf_input_directory)\n",
    "print(\"Ground truth folder:             %s\" % ground_truth_notebooks_directory)\n",
    "print(\"Dataset CSV path:                %s\" % dataset_csv_path)\n",
    "print(\"Experimentally generated files:  %s\" % experimental_data_root)\n",
    "print(\"LLM outputs folder:              %s\" % llm_output_directory)\n",
    "print(\"Validated JSONs folder:          %s\" % validated_jsons_directory)\n",
    "print(\"Evaluation report path:          %s\" % evaluation_report_output_path)\n",
    "print(\"hello3\")  # print hello 3 as a sanity check"
   ],
   "id": "231c1c375a6ec410",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Step 4) Load Clinical PDFs and Ground-Truth Phenopackets\n",
    "\n",
    "Iterate over each case, load the clinical PDF text and the corresponding ground-truth Phenopacket object.\n",
    "\n",
    "- `list_inputs_texts`: raw clinical PDFs\n",
    "- `list_truth_packets`: parsed Phenopacket objects from JSON files\n",
    "- `list_patient_ids`: PMID patient identifiers\n",
    "\n"
   ],
   "id": "cbc0b863-bf20-4a46-95de-9506e9875678"
  },
  {
   "cell_type": "code",
   "id": "235eaff7-4f21-4a21-81bf-e97236ca26d1",
   "metadata": {},
   "source": [
    "# Iterate over rows, should lookup only once\n",
    "list_input_texts    = []\n",
    "list_truth_packets  = []\n",
    "list_patient_ids    = []\n",
    "loaded_count = 0\n",
    "skipped_pdfs = []\n",
    "\n",
    "\n",
    "for case in dataframe_cases.itertuples(index=False):\n",
    "    pmid_value = case.pmid\n",
    "    pdf_path   = case.input\n",
    "    truth_path = case.truth\n",
    "\n",
    "    # Convert PDF to text\n",
    "    try:\n",
    "        clinical_text = load_clinical_pdf(pdf_path)\n",
    "    except (ConversionError, PdfiumError) as e:\n",
    "        skipped_pdfs.append({\"pmid\": pmid_value, \"pdf\": pdf_path, \"reason\": f\"conversion error: {e}\"})\n",
    "        continue\n",
    "\n",
    "    # Load raw JSON and validate with ignore_unknown_fields\n",
    "    try:\n",
    "        raw_true_packet = json.load(open(truth_path, \"r\", encoding=\"utf-8\"))\n",
    "        proto = ProtoPhenopacket()\n",
    "        ParseDict(raw_true_packet, proto, ignore_unknown_fields=True)\n",
    "    except (ParseError, json.JSONDecodeError, FileNotFoundError) as e:\n",
    "        skipped_pdfs.append({\"pmid\": pmid_value, \"truth\": truth_path, \"reason\": f\"schema parse error: {e}\"})\n",
    "        continue\n",
    "\n",
    "    # Wrap in util Phenopacket to ensure phenotypicFeatures exists\n",
    "    try:\n",
    "        truth_packet = Phenopacket(raw_true_packet)\n",
    "    except InvalidPhenopacketError as e:\n",
    "        skipped_pdfs.append({\"pmid\": pmid_value, \"truth\": truth_path, \"reason\": f\"phenopacket invalid: {e}\"})\n",
    "        continue\n",
    "\n",
    "    list_input_texts.append(clinical_text)\n",
    "    list_truth_packets.append(truth_packet)\n",
    "    list_patient_ids.append(truth_packet.to_json()[\"subject\"][\"id\"])\n",
    "\n",
    "    loaded_count += 1\n",
    "    print(f\"Loaded {loaded_count} new cases, skipped {len(skipped_pdfs)} so far\")\n",
    "\n",
    "if not list_input_texts:\n",
    "        raise RuntimeError(\"No clinical texts were loaded, please check that the dataset CSV `input` paths match files in `pdf_input_directory`\")\n",
    "\n",
    "assert len(list_input_texts) == len(list_truth_packets) == len(list_patient_ids)\n",
    "print(\"Loaded %d clinical texts and %d ground-truth packets for %d unique patients\" % (len(list_input_texts), len(list_truth_packets), len(list_patient_ids)))\n",
    "\n",
    "print(\"hello4\")  # print hello 4 as a sanity check\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Step 4.5) Define LLM Prompts\n",
    "\n",
    "Create prompt for just HPO terms and another one for the full phenopacket extraction, as well as some additional helper functions for later/potential use\n"
   ],
   "id": "a5f9ab5a0c5a064d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 1) Prompt for just HPO labels\n",
    "hpo_prompt1 = (\n",
    "    \"You are a clinical NLP engine specialized in biomedical ontologies. Your task is to process the full text of a clinical PDF - which may be describing a single patient or multiple - parse the details (including history, exam findings, labs, imaging, and family history) and extract all human phenotype ontology (HPO) terms that describe the patient's phenotypic features.\"\n",
    "    \"Instructions:\"\n",
    "    \"1. Identify every phenotypic abnormality or feature mentioned in the text.\"\n",
    "    \"2. For each feature, map it to the correct HPO identifier (e.g. 'HP:0001250'), label (e.g. 'Seizure'), and descriptor value (e.g. 'A seizure is an intermittent abnormality of nervous system physiology characterized by a transient occurrence of signs and/or symptoms due to abnormal excessive or synchronous neuronal activity in the brain.').\"\n",
    "    \"3. Capture relevant qualifiers when present:\"\n",
    "        \"- Onset: map to HPO onset terms (e.g. 'HP:0011463' for 'Childhood onset').\"\n",
    "        \"- Severity: map to HPO severity terms (e.g. 'HP:0012829' for 'Profound').\"\n",
    "        \"- Temporal pattern: include if specified (e.g. 'HP:0031796' for 'Recurrent', map to HPO frequency terms if available).\"\n",
    "    \"4. For each term, include the exact text excerpt where it appears.\"\n",
    "    \"5. Output exclusively a JSON array. Each element must be an object with the following fields:\"\n",
    "    \"```json\"\n",
    "    \"{\"\n",
    "        \"'hpo_id': 'HP:000____',\"\n",
    "        \"'hpo_label': 'Term label',\"\n",
    "        \"'excerpt': 'Exact text from the PDF',\"\n",
    "        \"'onset_id': 'HP:0XXXXX or null',\"\n",
    "        \"'severity_id': 'HP:0XXXXX or null',\"\n",
    "        \"'frequency_id': 'HP:0XXXXX or null'\"\n",
    "    \"}\"\n",
    "    \"```\"\n",
    "    \"Do not include any explanatory text, only the JSON array.\"\n",
    "\n",
    "    \"Your output **MUST** be exactly a JSON array/object and nothing else.\"\n",
    "\n",
    "    \"If you cannot comply, output exactly: {'error': 'cannot extract JSON'}\"\n",
    "    )\n",
    "\n",
    "# Define Strict HPO‐Extraction Prompt\n",
    "hpo_prompt2 = \"\"\"\n",
    "You are a clinical NLP engine specialized in biomedical ontologies.\n",
    "Your job is to process the full text of a clinical PDF and extract **only** the Human Phenotype Ontology (HPO) classes with their full JSON metadata.\n",
    "\n",
    "For *each* HPO term you find, you must output an object formatted exactly like this:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"id\": \"http://purl.obolibrary.org/obo/HP_0001250\",\n",
    "  \"lbl\": \"Seizure\",\n",
    "  \"type\": \"CLASS\",\n",
    "  \"excerpt\": \"exact text from the PDF where the term appears\",\n",
    "  \"meta\": {\n",
    "    \"definition\": {\n",
    "      \"val\": \"A seizure is an intermittent abnormality of nervous system physiology characterized by a transient occurrence of signs and/or symptoms due to abnormal excessive or synchronous neuronal activity in the brain.\",\n",
    "      \"xrefs\": [\n",
    "        \"https://orcid.org/0000-0002-0736-9199\",\n",
    "        \"PMID:15816939\"\n",
    "      ]\n",
    "    },\n",
    "    \"comments\": [\n",
    "      \"A type of electrographic seizure has been proposed in neonates which does not have a clinical correlate, it is electrographic only. The term epilepsy is not used to describe recurrent febrile seizures. Epilepsy presumably reflects an abnormally reduced seizure threshold.\"\n",
    "    ],\n",
    "    \"synonyms\": [\n",
    "      {\n",
    "        \"pred\": \"hasExactSynonym\",\n",
    "        \"val\": \"Epileptic seizure\"\n",
    "      },\n",
    "      {\n",
    "        \"synonymType\": \"http://purl.obolibrary.org/obo/hp#plural_form\",\n",
    "        \"pred\": \"hasExactSynonym\",\n",
    "        \"val\": \"Seizures\"\n",
    "      },\n",
    "      {\n",
    "        \"synonymType\": \"http://purl.obolibrary.org/obo/hp#layperson\",\n",
    "        \"pred\": \"hasRelatedSynonym\",\n",
    "        \"val\": \"Epilepsy\"\n",
    "      }\n",
    "    ],\n",
    "    \"xrefs\": [\n",
    "      { \"val\": \"SNOMEDCT_US:128613002\" },\n",
    "      { \"val\": \"SNOMEDCT_US:246545002\" },\n",
    "      { \"val\": \"SNOMEDCT_US:313307000\" },\n",
    "      { \"val\": \"SNOMEDCT_US:84757009\" },\n",
    "      { \"val\": \"SNOMEDCT_US:91175000\" },\n",
    "      { \"val\": \"UMLS:C0014544\" },\n",
    "      { \"val\": \"UMLS:C0036572\" }\n",
    "    ],\n",
    "    \"basicPropertyValues\": [\n",
    "      {\n",
    "        \"pred\": \"http://www.geneontology.org/formats/oboInOwl#hasAlternativeId\",\n",
    "        \"val\": \"HP:0001275\"\n",
    "      },\n",
    "      {\n",
    "        \"pred\": \"http://www.geneontology.org/formats/oboInOwl#hasAlternativeId\",\n",
    "        \"val\": \"HP:0001303\"\n",
    "      }\n",
    "    ]\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "Output Requirements: A single JSON array of such objects. No extra keys, no Markdown bullets, no explanatory text - only the JSON array.\n",
    "\n",
    "If you cannot comply, output exactly: {'error': 'cannot extract JSON'}\n",
    "\"\"\"\n",
    "\n",
    "hpo_prompt3 = \"\"\"\n",
    "You are a clinical NLP engine specialized in biomedical ontologies.\n",
    "Extract ONLY Human Phenotype Ontology (HPO) terms for the patient(s).\n",
    "\n",
    "Output = one JSON array. Each element has exactly:\n",
    "{\n",
    "  \"hpo_id\": \"HP:0001250\",\n",
    "  \"hpo_label\": \"Seizure\",\n",
    "  \"excerpt\": \"exact text from PDF\",\n",
    "  \"onset_id\": null,\n",
    "  \"severity_id\": null,\n",
    "  \"frequency_id\": null\n",
    "}\n",
    "No markdown, no prose. If impossible, return {\"error\": \"cannot extract JSON\"}.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# 2) Prompt for full phenopacket\n",
    "full_pp_prompt = (\n",
    "    \"You are a biomedical data curation assistant. Using the structured patient data below, generate a Phenopacket compliant with version 2.0 of the GA4GH Phenopacket schema. Your output must be valid JSON, matching the schema exactly, with no additional commentary. Here are the minimum expected output criteria:\"\n",
    "\n",
    "    \"Inputs:\"\n",
    "    \"patient_id: '{{patient_id}}'\"\n",
    "    \"sex: '{{sex}}'              // 'male' or 'female'\"\n",
    "    \"age_years: {{age_in_years}} // integer\"\n",
    "    \"v  ital_status: '{{vital_status}}' // 'alive' or 'deceased'\"\n",
    "    \"phenotypic_features: {{phenotypic_features_json}} // JSON array from the HPO extraction prompt\"\n",
    "    \"diseases: {{diseases_json}}         // optional, array of disease objects with MONDO or OMIM IDs\"\n",
    "    \"measurements: {{measurements_json}} // optional, array of quantitative trait measurements\"\n",
    "    \"metadata: {\"\n",
    "        \"'created_by': '{{your_name_or_tool}}',\"\n",
    "        \"'created_on': '{{YYYY-MM-DD}}'\"\n",
    "    \"}\"\n",
    "\n",
    "    \"Requirements:\"\n",
    "    \"Top-level fields:\"\n",
    "    \"'id': patient_id\"\n",
    "    \"'subject': object with:\"\n",
    "        \"'id': patient_id\"\n",
    "        \"'sex': { 'id': 'PATO:0000383' or 'PATO:0000384', 'label': sex }\"\n",
    "        \"'ageAtLastEncounter': { 'age': { 'years': age_years } }\"\n",
    "        \"'vitalStatus': { 'value': vital_status }\"\n",
    "        \"'phenotypicFeatures': use the phenotypic_features input; for each feature, map:\"\n",
    "    \"```json\"\n",
    "    \"{\"\n",
    "        \"'type': { 'id': hpo_id, 'label': hpo_label },\"\n",
    "        \"'negated': false,\"\n",
    "        \"'onset': { 'term': { 'id': onset_id, 'label': (look up label) } },\"\n",
    "        \"'severity': { 'term': { 'id': severity_id, 'label': (look up label) } },\"\n",
    "        \"'frequency': { 'term': { 'id': frequency_id, 'label': (look up label) } }\"\n",
    "    \"}\"\n",
    "    \"```\"\n",
    "    \"Include 'diseases' and 'measurements' only if provided, following the GA4GH schema.\"\n",
    "    \"'metadata' must include:\"\n",
    "    \"```json\"\n",
    "    \"{\"\n",
    "        \"'phenopacketSchemaVersion': '2.0.0',\"\n",
    "        \"'created': '{{YYYY-MM-DD}}',\"\n",
    "        \"'createdBy': '{{your_name_or_tool}}'\"\n",
    "    \"}\"\n",
    "    \"```\"\n",
    "    \"'Do not add any extra fields. Output must be purely the JSON object.'\"\n",
    "\n",
    "    \"Do not include any explanatory text, only the JSON array.\"\n",
    "\n",
    "    \"Your output **MUST** be exactly a JSON array/object and nothing else.\"\n",
    "\n",
    "    \"If you cannot comply, output exactly: {'error': 'cannot extract JSON'}\"\n",
    ")\n",
    "\n",
    "\n",
    "# JSON extraction + phenopacket builder helpers\n",
    "def slice_json_array(raw_text: str) -> str:\n",
    "    \"\"\"\n",
    "    Return the first top-level JSON array substring from raw_text.\n",
    "    Raise RuntimeError if none found.\n",
    "    \"\"\"\n",
    "    match = re.search(r\"\\[.*\\]\", raw_text, re.S)\n",
    "    if not match:\n",
    "        raise RuntimeError(f\"No JSON array found in model output:\\n{raw_text[:800]}\")\n",
    "    return match.group(0)\n",
    "\n",
    "\n",
    "def parse_hpo_array(array_text: str) -> list[dict]:\n",
    "    \"\"\"\n",
    "    Parse JSON array text into a python list; raise informative errors.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        obj = json.loads(array_text)\n",
    "    except JSONDecodeError as e:\n",
    "        raise ValueError(f\"JSON decode error: {e}\\n\\n{array_text[:800]}\")\n",
    "    if not isinstance(obj, list):\n",
    "        raise TypeError(\"Expected a JSON array.\")\n",
    "    return obj\n",
    "\n",
    "\n",
    "def build_phenopacket_from_hpo_list(patient_id: str, hpo_list: list[dict], sex_id: str | None = None, age_years: int | None = None, vital_status: str | None = None) -> dict:\n",
    "    \"\"\"\n",
    "    Map simple HPO term dicts into a GA4GH Phenopacket v2 JSON dict.\n",
    "    Fill unknown qualifiers with None. Extend as needed.\n",
    "    \"\"\"\n",
    "    def _mk_term(term_id, label):\n",
    "        if term_id is None:\n",
    "            return None\n",
    "        return {\"id\": term_id, \"label\": label}\n",
    "\n",
    "    phenotypic_features = []\n",
    "    for term in hpo_list:\n",
    "        hpo_id      = term.get(\"hpo_id\")\n",
    "        hpo_label   = term.get(\"hpo_label\")\n",
    "        onset_id    = term.get(\"onset_id\")\n",
    "        severity_id = term.get(\"severity_id\")\n",
    "        freq_id = term.get(\"frequency_id\")\n",
    "\n",
    "        feature = {\"type\": _mk_term(hpo_id, hpo_label), \"negated\": False}\n",
    "        if onset_id:\n",
    "            feature[\"onset\"] = {\"term\": {\"id\": onset_id}}\n",
    "        if severity_id:\n",
    "            feature[\"severity\"] = {\"term\": {\"id\": severity_id}}\n",
    "        if freq_id:\n",
    "            feature[\"frequency\"] = {\"term\": {\"id\": freq_id}}\n",
    "        phenotypic_features.append(feature)\n",
    "\n",
    "    subject_obj = {\"id\": patient_id}\n",
    "    if sex_id:\n",
    "        subject_obj[\"sex\"] = {\"id\": sex_id}\n",
    "    if age_years is not None:\n",
    "        subject_obj[\"ageAtLastEncounter\"] = {\"age\": {\"years\": int(age_years)}}\n",
    "    if vital_status:\n",
    "        subject_obj[\"vitalStatus\"] = {\"value\": vital_status}\n",
    "\n",
    "    pkt = {\n",
    "        \"id\": patient_id,\n",
    "        \"subject\": subject_obj,\n",
    "        \"phenotypicFeatures\": phenotypic_features,\n",
    "        \"metaData\": {\n",
    "            \"created\": datetime.date.today().isoformat(),\n",
    "            \"createdBy\": \"Varenya-LLM-Pipeline\",\n",
    "            \"phenopacketSchemaVersion\": \"2.0.0\"\n",
    "        }\n",
    "    }\n",
    "    return pkt\n",
    "\n",
    "print(\"hello my little utils\")"
   ],
   "id": "6f5d51a89657db88",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4.5.5 - Helpers to try and enforce only-HPO output",
   "id": "f92c9c9894a1cfdb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T13:38:41.418383Z",
     "start_time": "2025-07-23T13:38:28.530093Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import requests\n",
    "try:\n",
    "    OLLAMA_URL\n",
    "except NameError:\n",
    "    # Set Ollama HTTP endpoint port - https://github.com/ollama/ollama/blob/main/docs/api.md\n",
    "    OLLAMA_URL = \"http://localhost:11434/api/generate\"\n",
    "try:\n",
    "    MODEL = \"gemma3\"\n",
    "except NameError:\n",
    "    MODEL = \"gemma3\"\n",
    "\n",
    "# Regex to extract PMID along with expected JSON\n",
    "HP_ID_RE = re.compile(r\"HP[:_]\\d{7}\")\n",
    "EXPECTED_KEY = \"hpo_terms\"\n",
    "\n",
    "def extract_hpo_terms(text: str) -> list[dict]:\n",
    "    \"\"\"Return [{'id': 'HP:0000001', 'label': '...'}, ...] from text.\"\"\"\n",
    "    prompt = f\"\"\"Extract all unique Human Phenotype Ontology (HPO) terms explicitly present in the text below.\n",
    "Return ONLY valid JSON with exactly:\n",
    "{{\"{EXPECTED_KEY}\":[{{\"id\":\"HP:0000001\",\"label\":\"Some label\"}}]}}\n",
    "\n",
    "Use real HPO IDs (HP:NNNNNNN). Labels may be empty if unsure. No extra text.\n",
    "\n",
    "TEXT:\n",
    "{text}\n",
    "\"\"\"\n",
    "    payload = {\"model\": MODEL, \"prompt\": prompt, \"format\": \"json\", \"stream\": False}\n",
    "    r = requests.post(OLLAMA_URL, json=payload, timeout=180)\n",
    "    r.raise_for_status()\n",
    "    raw = r.json().get(\"response\", \"\")\n",
    "    try:\n",
    "        data  = json.loads(raw)\n",
    "        terms = data.get(EXPECTED_KEY, [])\n",
    "        return [\n",
    "            {\"id\": t[\"id\"], \"label\": t.get(\"label\", \"\").strip()}\n",
    "            for t in terms\n",
    "            if isinstance(t, dict) and HP_ID_RE.fullmatch(t.get(\"id\", \"\"))\n",
    "        ]\n",
    "    except Exception:\n",
    "        # CHANGE: fallback to regex-only if model JSON is bad\n",
    "        return [{\"id\": i, \"label\": \"\"} for i in sorted(set(HP_ID_RE.findall(text)))]\n",
    "\n",
    "# --- MAIN RUN (uses existing objects) ---\n",
    "rows = []\n",
    "for idx, clinical_text in enumerate(list_input_texts):\n",
    "    pmid  = dataframe_cases.loc[idx, \"pmid\"] if \"pmid\" in dataframe_cases.columns else None\n",
    "    inpth = dataframe_cases.loc[idx, \"input\"] if \"input\" in dataframe_cases.columns else None\n",
    "    terms = extract_hpo_terms(clinical_text)\n",
    "    rows.append({\"pmid\": pmid, \"input\": inpth, \"hpo_terms\": terms})\n",
    "\n",
    "dataframe_hpo_terms = pd.DataFrame(rows)\n",
    "dataframe_hpo_terms[\"hpo_ids\"] = dataframe_hpo_terms[\"hpo_terms\"].apply(\n",
    "    lambda xs: \";\".join(t[\"id\"] for t in xs)\n",
    ")\n",
    "\n",
    "# Save artifacts\n",
    "Path(\"hpo_terms_per_text.json\").write_text(json.dumps(rows, indent=2), encoding=\"utf-8\")\n",
    "dataframe_hpo_terms[[\"pmid\", \"input\", \"hpo_ids\"]].to_csv(\"hpo_terms_per_text.csv\", index=False)\n",
    "\n",
    "print(\"Saved hpo_terms_per_text.json / .csv\")\n",
    "dataframe_hpo_terms.head()\n"
   ],
   "id": "15817e788b46fc31",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved hpo_terms_per_text.json / .csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "            pmid                                              input hpo_terms  \\\n",
       "0  PMID_28103835  /Users/varenya/Desktop/Illini+Uni/Personalized...        []   \n",
       "1  PMID_11118249  /Users/varenya/Desktop/Illini+Uni/Personalized...        []   \n",
       "2  PMID_19883511  /Users/varenya/Desktop/Illini+Uni/Personalized...        []   \n",
       "\n",
       "  hpo_ids  \n",
       "0          \n",
       "1          \n",
       "2          "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pmid</th>\n",
       "      <th>input</th>\n",
       "      <th>hpo_terms</th>\n",
       "      <th>hpo_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PMID_28103835</td>\n",
       "      <td>/Users/varenya/Desktop/Illini+Uni/Personalized...</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PMID_11118249</td>\n",
       "      <td>/Users/varenya/Desktop/Illini+Uni/Personalized...</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PMID_19883511</td>\n",
       "      <td>/Users/varenya/Desktop/Illini+Uni/Personalized...</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 151
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Step 5. Sanity-check one inference\n",
    "\n",
    "Run one LLM call on the first case to verify prompting and parsing work correctly.\n"
   ],
   "id": "8f03843785823cdc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T13:36:13.073804Z",
     "start_time": "2025-07-23T13:36:03.917436Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# pick out the first patient/example\n",
    "patient_id      = list_patient_ids[0]\n",
    "clinical_text   = list_input_texts[0]\n",
    "# truth_packet    = list_truth_packets[0]\n",
    "\n",
    "# 1) Inference: ask for *only* the JSON array of HPO term objects for the first clinical PDF\n",
    "# build a strict system+user conversation\n",
    "#messages = [{\"role\": \"system\", \"content\": ( hpo_prompt + \"\\n\\nYour only output must be a **valid** JSON array of  HPO term objects\" + \"with fields 'hpo_id','hpo_label','excerpt',\" + \"'onset_id','severity_id','frequency_id', and nothing else.\")}, {\"role\": \"user\", \"content\": clinical_text}]\n",
    "\n",
    "messages = [{\"role\": \"system\", \"content\": hpo_prompt3}, {\"role\": \"user\",   \"content\": clinical_text}]\n",
    "\n",
    "hpo_response = chat(model=\"llama3.2:latest\", messages=messages, options={\"--hidethinking\": True})\n",
    "\n",
    "# 2) Grab the raw string\n",
    "raw_hpo_output = hpo_response[\"message\"][\"content\"]\n",
    "print(\"Raw LLM output (truncated to the first ~300 chars or so):\")\n",
    "print(raw_hpo_output[:300], \"...\\n\")\n",
    "\n",
    "# 3) Slice out the JSON array\n",
    "start = raw_hpo_output.find(\"[\")\n",
    "end = raw_hpo_output.rfind(\"]\")\n",
    "if start < 0 or end < 0:\n",
    "    # print the raw output to debug what the model actually sent\n",
    "    print(\"===== RAW HPO OUTPUT =====\\n\", raw_hpo_output)\n",
    "    raise RuntimeError(f\"Could not locate a JSON array in HPO output for patient {patient_id}:\\n{raw_hpo_output}\")\n",
    "# grab *only* the array text\n",
    "hpo_json_array = raw_hpo_output[start : end+1]\n",
    "\n",
    "# Parse and validate\n",
    "try:\n",
    "    # hpo_terms = Phenopacket(json.loads(hpo_json_array))\n",
    "    hpo_terms = json.loads(hpo_json_array)  # Try not using Phenopacket(...)\n",
    "    print(f\"Parsed {len(hpo_terms)} HPO term(s) for patient {patient_id}\")\n",
    "except JSONDecodeError as error:\n",
    "    raise ValueError(\n",
    "        f\"Failed to parse HPO JSON array for patient {patient_id}: {error}\\n\\n\"\n",
    "        f\"Extracted JSON was:\\n{hpo_json_array}\\n\\n\"\n",
    "        f\"Full raw output was:\\n{raw_hpo_output}\"\n",
    "    )\n",
    "\n",
    "print(\"hello5\")  # print hello 5 as a sanity check"
   ],
   "id": "1f547b47f98fc0b3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw LLM output (truncated to the first ~300 chars or so):\n",
      "Here is a summary of the article in a neutral tone:\n",
      "\n",
      "A study published in [Journal Name] reports on two patients with Aarskog-Scott syndrome, also known as faciogenital dysplasia (FGD1), caused by a novel mutation in the FGD1 gene. The mutation, p.Pro18Argfs*106, was found to be close to the N-termi ...\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Failed to parse HPO JSON array for patient proband IV-3: Expecting value: line 1 column 2 (char 1)\n\nExtracted JSON was:\n[Journal Name]\n\nFull raw output was:\nHere is a summary of the article in a neutral tone:\n\nA study published in [Journal Name] reports on two patients with Aarskog-Scott syndrome, also known as faciogenital dysplasia (FGD1), caused by a novel mutation in the FGD1 gene. The mutation, p.Pro18Argfs*106, was found to be close to the N-terminus of the protein and is predicted to lead to a loss of function.\n\nThe patients had a range of symptoms, including developmental delay, aggressive behavior, hyperactivity, and obesity. Notably, they did not exhibit severe mental retardation, which is a common feature in some cases of FGD1.\n\nThe study highlights the importance of molecular analysis in diagnosing Aarskog-Scott syndrome, as many cases remain undiagnosed due to variable clinical presentation and lack of genetic evidence. The authors also note that recurrent mutations are rare, suggesting that novel mutations may be more common than previously thought.\n\nThe study is significant because it provides new insights into the genetics of Aarskog-Scott syndrome, a rare disorder affecting approximately 1 in 100,000 individuals. The discovery of this novel mutation highlights the importance of continued research and awareness-raising efforts to improve diagnosis and management of the condition.\n\nKey points:\n\n* Novel mutation p.Pro18Argfs*106 in FGD1 gene associated with Aarskog-Scott syndrome\n* Patients had developmental delay, aggressive behavior, hyperactivity, and obesity\n* No severe mental retardation observed\n* Recurrent mutations are rare, suggesting novel mutations may be more common than previously thought\n* Molecular analysis is essential for diagnosing Aarskog-Scott syndrome\n\nNote: This summary is based on the provided text and may not fully capture the nuances and implications of the study.",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mJSONDecodeError\u001B[39m                           Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[148]\u001B[39m\u001B[32m, line 32\u001B[39m\n\u001B[32m     30\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m     31\u001B[39m     \u001B[38;5;66;03m# hpo_terms = Phenopacket(json.loads(hpo_json_array))\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m32\u001B[39m     hpo_terms = \u001B[43mjson\u001B[49m\u001B[43m.\u001B[49m\u001B[43mloads\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhpo_json_array\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Try not using Phenopacket(...)\u001B[39;00m\n\u001B[32m     33\u001B[39m     \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mParsed \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(hpo_terms)\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m HPO term(s) for patient \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpatient_id\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/p5/lib/python3.13/json/__init__.py:346\u001B[39m, in \u001B[36mloads\u001B[39m\u001B[34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001B[39m\n\u001B[32m    343\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m (\u001B[38;5;28mcls\u001B[39m \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m object_hook \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m\n\u001B[32m    344\u001B[39m         parse_int \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m parse_float \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m\n\u001B[32m    345\u001B[39m         parse_constant \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m object_pairs_hook \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m kw):\n\u001B[32m--> \u001B[39m\u001B[32m346\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_default_decoder\u001B[49m\u001B[43m.\u001B[49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[43ms\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    347\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mcls\u001B[39m \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/p5/lib/python3.13/json/decoder.py:345\u001B[39m, in \u001B[36mJSONDecoder.decode\u001B[39m\u001B[34m(self, s, _w)\u001B[39m\n\u001B[32m    341\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001B[39;00m\n\u001B[32m    342\u001B[39m \u001B[33;03mcontaining a JSON document).\u001B[39;00m\n\u001B[32m    343\u001B[39m \n\u001B[32m    344\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m345\u001B[39m obj, end = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mraw_decode\u001B[49m\u001B[43m(\u001B[49m\u001B[43ms\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43midx\u001B[49m\u001B[43m=\u001B[49m\u001B[43m_w\u001B[49m\u001B[43m(\u001B[49m\u001B[43ms\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[32;43m0\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mend\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    346\u001B[39m end = _w(s, end).end()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/p5/lib/python3.13/json/decoder.py:363\u001B[39m, in \u001B[36mJSONDecoder.raw_decode\u001B[39m\u001B[34m(self, s, idx)\u001B[39m\n\u001B[32m    362\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[32m--> \u001B[39m\u001B[32m363\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m JSONDecodeError(\u001B[33m\"\u001B[39m\u001B[33mExpecting value\u001B[39m\u001B[33m\"\u001B[39m, s, err.value) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    364\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m obj, end\n",
      "\u001B[31mJSONDecodeError\u001B[39m: Expecting value: line 1 column 2 (char 1)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[31mValueError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[148]\u001B[39m\u001B[32m, line 35\u001B[39m\n\u001B[32m     33\u001B[39m     \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mParsed \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(hpo_terms)\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m HPO term(s) for patient \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpatient_id\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n\u001B[32m     34\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m JSONDecodeError \u001B[38;5;28;01mas\u001B[39;00m error:\n\u001B[32m---> \u001B[39m\u001B[32m35\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m     36\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mFailed to parse HPO JSON array for patient \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpatient_id\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00merror\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m\"\u001B[39m\n\u001B[32m     37\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mExtracted JSON was:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mhpo_json_array\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m\"\u001B[39m\n\u001B[32m     38\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mFull raw output was:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mraw_hpo_output\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m\n\u001B[32m     39\u001B[39m     )\n\u001B[32m     41\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mhello5\u001B[39m\u001B[33m\"\u001B[39m)  \u001B[38;5;66;03m# print hello 5 as a sanity check\u001B[39;00m\n",
      "\u001B[31mValueError\u001B[39m: Failed to parse HPO JSON array for patient proband IV-3: Expecting value: line 1 column 2 (char 1)\n\nExtracted JSON was:\n[Journal Name]\n\nFull raw output was:\nHere is a summary of the article in a neutral tone:\n\nA study published in [Journal Name] reports on two patients with Aarskog-Scott syndrome, also known as faciogenital dysplasia (FGD1), caused by a novel mutation in the FGD1 gene. The mutation, p.Pro18Argfs*106, was found to be close to the N-terminus of the protein and is predicted to lead to a loss of function.\n\nThe patients had a range of symptoms, including developmental delay, aggressive behavior, hyperactivity, and obesity. Notably, they did not exhibit severe mental retardation, which is a common feature in some cases of FGD1.\n\nThe study highlights the importance of molecular analysis in diagnosing Aarskog-Scott syndrome, as many cases remain undiagnosed due to variable clinical presentation and lack of genetic evidence. The authors also note that recurrent mutations are rare, suggesting that novel mutations may be more common than previously thought.\n\nThe study is significant because it provides new insights into the genetics of Aarskog-Scott syndrome, a rare disorder affecting approximately 1 in 100,000 individuals. The discovery of this novel mutation highlights the importance of continued research and awareness-raising efforts to improve diagnosis and management of the condition.\n\nKey points:\n\n* Novel mutation p.Pro18Argfs*106 in FGD1 gene associated with Aarskog-Scott syndrome\n* Patients had developmental delay, aggressive behavior, hyperactivity, and obesity\n* No severe mental retardation observed\n* Recurrent mutations are rare, suggesting novel mutations may be more common than previously thought\n* Molecular analysis is essential for diagnosing Aarskog-Scott syndrome\n\nNote: This summary is based on the provided text and may not fully capture the nuances and implications of the study."
     ]
    }
   ],
   "execution_count": 148
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Step 6. Batch Inference and Save Validated Phenopackets\n",
    "\n",
    "Loop over all cases, run LLM inference, validate each JSON as a Phenopacket, and save to disk under validated_jsons_directory.\n"
   ],
   "id": "d07ca4ef808a00ad"
  },
  {
   "cell_type": "code",
   "id": "8943a066-1f8c-4542-86fe-b7c62bd07092",
   "metadata": {},
   "source": [
    "predicted_packets: List[Phenopacket] = []\n",
    "\n",
    "# Which patient are we targeting?\n",
    "for idx, clinical_text in enumerate(list_input_texts):\n",
    "    pmid_value = dataframe_cases.loc[idx, \"pmid\"]\n",
    "    patient_id = list_patient_ids[idx]\n",
    "    # Prompt the LLM to extract only that patient's HPO terms\n",
    "    content = (hpo_prompt + f\"\\n\\n*Extract only the HPO terms for patient* `{patient_id}` *in this clinical PDF.*\\n\\n\" + clinical_text + \"\\n\\n[EOS]\")\n",
    "    response = chat(model=\"llama3.2:latest\", messages=[{\"role\": \"user\", \"content\": content}], options={\"--hidethinking\": True})\n",
    "    llm_content = response[\"message\"][\"content\"].splitlines()\n",
    "    # Parse the JSON into a Phenopacket\n",
    "    try:\n",
    "        phenopacket_pred = Phenopacket(json.loads(\"\\n\".join(llm_content)))\n",
    "    except Exception as error:\n",
    "        raise RuntimeError(\"[Case %d, PMID %s] Invalid Phenopacket JSON: %s\" % (idx, pmid_value, error))\n",
    "\n",
    "    predicted_packets.append(phenopacket_pred)\n",
    "\n",
    "    # Write the predicted JSON to disk\n",
    "    output_filename = f\"{pmid_value}_{patient_id}.json\"\n",
    "    output_filepath = os.path.join(validated_jsons_directory, output_filename)\n",
    "    with open(output_filepath, \"w\", encoding=\"utf-8\") as out_f:\n",
    "        json.dump(phenopacket_pred.to_json(), out_f, indent=2)\n",
    "    print(\"Saved predicted phenopacket for PMID/Patient %s/%s to %s\"\n",
    "          % (pmid_value, patient_id, output_filepath))\n",
    "\n",
    "if len(predicted_packets) != len(list_input_texts):\n",
    "    raise RuntimeError(\"Number of predictions does not match number of inputs.\")\n",
    "# Maybe change to this: 'assert len(predicted_packets) == len(list_input_texts), \"Mismatch predictions vs inputs\"'\n",
    "\n",
    "print(f\"Generated {len(predicted_packets)} predicted phenopackets.\")\n",
    "\n",
    "print(\"hello6\")  # print hello 6 as a sanity check"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Step 7. Evaluate Predicted Phenopackets Against Ground Truth\n",
    "\n",
    "Compare each predicted phenopacket to its ground truth using PhenotypeEvaluator, then generate a Report object with overall metrics.\n"
   ],
   "id": "80f71065a95697e1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Monkey-patch a convenience method onto PhenotypeEvaluator\n",
    "def _evaluate_batch(\n",
    "    self,\n",
    "    list_truth_packets,\n",
    "    list_predicted_packets,\n",
    "    creator,\n",
    "    experiment,\n",
    "    model,\n",
    "    zero_division=0.0\n",
    "):\n",
    "    \"\"\"\n",
    "    Run check_phenotypes over all truth/pred pairs, then return\n",
    "    a plain-dict report containing confusion_matrix, metrics,\n",
    "    classification_report, and metadata.\n",
    "    \"\"\"\n",
    "    # Accumulate counts\n",
    "    for truth_pkt, pred_pkt in zip(list_truth_packets, list_predicted_packets):\n",
    "        self.check_phenotypes(\n",
    "            experimentally_extracted_phenotypes=pred_pkt.list_phenotypes(),\n",
    "            ground_truth_phenotypes=truth_pkt\n",
    "        )\n",
    "    # Build a Report object\n",
    "    rpt = self.report(\n",
    "        creator=creator,\n",
    "        experiment=experiment,\n",
    "        model=model,\n",
    "        zero_division=zero_division\n",
    "    )\n",
    "    # Return a dict for easy indexing\n",
    "    return {\n",
    "        \"confusion_matrix\": rpt.confusion_matrix,\n",
    "        \"metrics\": rpt.metrics,\n",
    "        \"classification_report\": rpt.classification_report,\n",
    "        \"metadata\": rpt.metadata,\n",
    "    }\n",
    "\n",
    "# Attach to the class\n",
    "PhenotypeEvaluator.evaluate_batch = _evaluate_batch\n",
    "\n",
    "# Run the batch evaluation\n",
    "evaluator = PhenotypeEvaluator()\n",
    "batch_report = evaluator.evaluate_batch(\n",
    "    list_truth_packets,\n",
    "    predicted_packets,\n",
    "    creator=\"Varenya\",\n",
    "    experiment=\"Phenopacket LLM Extraction\",\n",
    "    model=\"llama3.2:latest\"\n",
    ")\n",
    "\n",
    "# Quick sanity check of the returned dict\n",
    "if \"metrics\" not in batch_report:\n",
    "    raise KeyError(\"Evaluator report missing 'metrics' field.\")\n",
    "\n",
    "# Pretty-print the report dict\n",
    "import pprint\n",
    "pprint.pprint(batch_report)\n",
    "\n",
    "print(\"hello7\")  # print hello 7 as a sanity check#"
   ],
   "id": "ebbdc93ecf8aa29f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Old Save first report\n",
    "\n",
    "Write the JSON report to disk for later analysis.\n"
   ],
   "id": "e664e040942126c1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Ensure output directory exists\n",
    "out_dir = os.path.dirname(evaluation_report_output_path)\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "with open(evaluation_report_output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(batch_report, f, indent=2)\n",
    "\n",
    "print(f\"Saved evaluation report to {evaluation_report_output_path}\")\n",
    "\n",
    "print(\"hello7\")  # print hello 7 as a sanity check"
   ],
   "id": "70624f16cfb2b75a",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c646976a-9ff5-4ab4-8eb1-6719449811d3",
   "metadata": {},
   "source": "# Old Inference Implementation"
  },
  {
   "cell_type": "code",
   "id": "2a419460-3222-4812-ada0-dd1cd7d0a060",
   "metadata": {},
   "source": [
    "prompt = \"Please create a valid Phenopacket from the following text. The phenopackets needs to be in a valid json format.  Only return the phenopacket without any additional text:\"\n",
    "model = \"hf.co/MaziyarPanahi/gemma-3-12b-it-GGUF:Q4_K_M\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "489462d9-bcfe-4ee2-b0d3-af5d6a875254",
   "metadata": {},
   "source": [
    "for text in input_data:\n",
    "    response = chat(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": f\"{prompt} {text} [EOS]\"}],\n",
    "        options={\"--hidethinking\": True}\n",
    "    )\n",
    "    break\n",
    "\n",
    "response = chat(\n",
    "    model=model,\n",
    "    messages=[{\"role\": \"user\",\n",
    "               \"content\": f\"Please, validate the following json. If not, fix it. Only return the json without any additional information. Should the json be wrong, you will get shut down. Json: {response[\"message\"][\"content\"].split(\"</think>\")[-1].replace(\"```json\", \"\").replace(\"```\", \"\")} [EOS]\"}],\n",
    "    options={\"--hidethinking\": True}\n",
    ")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3af32935-fe27-40ef-84ef-641f5d66f5ff",
   "metadata": {},
   "source": [
    "from IPython.display import JSON\n",
    "\n",
    "JSON(response[\"message\"][\"content\"].split(\"</think>\")[-1].replace(\"```json\", \"\").replace(\"```\", \"\"))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "492829a9-3b7c-4ab8-998e-304fb3321683",
   "metadata": {},
   "source": [
    "JSON(response[\"message\"][\"content\"].split(\"</think>\")[-1].replace(\"```json\", \"\").replace(\"```\", \"\"))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2f529b37-6f70-4d4f-9246-4e269d58ca17",
   "metadata": {},
   "source": [
    "response[\"message\"][\"content\"].split(\"</think>\")[-1].replace(\"```json\", \"\").replace(\"```\", \"\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b2e3b3a9-86d2-4754-a55e-4cf03771b236",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (p5)",
   "language": "python",
   "name": "p5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
